{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5f4f4a-5890-451c-8869-24606ef9f396",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#getting OPEN AI KEY and ENDPOINT\n",
    "\n",
    "from helper import get_openai_api_key\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc9b4f4-64d4-4266-9889-54db90e00ee9",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio #is that jupyter runs an even loop behind the scenes\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c7f012d-dcd3-4881-a568-72dd27d79159",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader # use for read the pdf offered by llamaindex\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"Design of a cooling system for a hybrid-powered vehicle.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define LLM and Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a537bc0-78ee-4dda-a43f-60fd80062df6",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter #split on the order of the sentences\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024) #chunk size = 1024\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0660ee-b231-4351-b158-d8ad023e00b5",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding #use as a embedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\") #llm -> OpenAI ,model-> gpt-3.5-turbo\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\") # embedding model->OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Summary Index and Vector Index over the Same Data and also have more explanation with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d01b01-bc74-432a-8d92-07b9e86498b0",
   "metadata": {
    "height": 251,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    these have 2 indexes summery index and vector index\n",
    "    those are having a different retrival behaviours\n",
    "    vector index--> as a text embeddings and its core anstraction and llama index and a core abstraction for building any sort of RAG system \n",
    "    summaru index--> quaring it will return all the nodes currently in the index \n",
    "        and it does'nt necessarily depend on the user query but will return all the nodes \n",
    "        that's currently in the index.\n",
    "\"\"\"\n",
    "\n",
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44cd7046-c714-4920-b077-b3ded917862f",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define Query Engines and Set Metadata\n",
    "\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True, #enforce faster query generation by leveraging async capabilities\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a1d6d75-247e-426a-8ef4-b49225c24796",
   "metadata": {
    "height": 302,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool #query tool mean just the query engine with metadata\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(#useful for summerization questions related to Meta GPT paper\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to MetaGPT\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(#useful for retriving specific context from the Meta GPT paper\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Router Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00734d7c-638a-4d63-ab1f-7f5a92a65119",
   "metadata": {
    "height": 234,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine #se\n",
    "from llama_index.core.selectors import LLMSingleSelector # have various selectors please see screenshots\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine( #router query engine takes in a selector type as well as a set of query engine tools.\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe3f0a76-68a8-444d-867f-d084bb3ff112",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: This choice indicates that the document is useful for summarization questions related to MetaGPT..\n",
      "\u001b[0mThe document discusses the design and testing of a cooling system for a hybrid-powered vehicle that utilizes waste energy from exhaust gas and solar energy to power the electric compressor of the refrigeration system. It explores various refrigeration system cycles such as vapor compression, absorption, Stirling, and desiccant cycles as alternatives for vehicle cooling. The study aims to increase engine efficiency, reduce fuel consumption, and provide a sustainable solution for vehicle air conditioning systems by incorporating clean energy sources and waste heat recovery mechanisms.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3fedea0-f2a9-46bb-8aaf-287df65b8fff",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af8c31b3-8e22-4ad9-9825-b8de21bd03c0",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to MetaGPT.\n",
      "\u001b[0m- Project focuses on designing a cooling system for a hybrid-powered vehicle using kinetic energy from exhaust gases and solar energy.\n",
      "- System aims to reduce engine load, fuel consumption, and increase engine efficiency.\n",
      "- Utilizes waste heat recovery and clean energy utilization to operate the electric compressor of the refrigeration system.\n",
      "- Study shows improved engine efficiency and a 5.18% increase in the coefficient of performance compared to conventional systems.\n",
      "- Various refrigeration cycles like vapor compression, absorption, Stirling, and desiccant are discussed as alternatives.\n",
      "- Experimental setup involves components for solar energy conversion and recovering kinetic and thermal energy from the engine.\n",
      "- System includes a diesel engine, photovoltaic cells, and a vapor compression system.\n",
      "- Kia Carnival diesel engine is used due to its higher density and exhaust gas temperature.\n",
      "- Photovoltaic system consists of a panel, charge controller, battery, and interconnection wiring.\n",
      "- DC compressor is used to operate the cooling system, powered by the solar panels.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"give me summery in point form?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Response using utils files and all the queries add to the utils file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8f92e0b-1c54-489b-b8dd-41ebaafb380a",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "#we can use helper function for getting router query engine and named utils file.we can add all the data like query tools selectors like that things to utils file and we can retrive data from utils\n",
    "\n",
    "from utils import get_router_query_engine\n",
    "\n",
    "query_engine = get_router_query_engine(\"Design of a cooling system for a hybrid-powered vehicle.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec1a43f3-77dc-472a-8adc-56551c00a0ff",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The question is asking for information about a specific PDF, which would require retrieving specific context from the MetaGPT paper..\n",
      "\u001b[0mThe PDF document discusses the design of a cooling system for a hybrid-powered vehicle. It includes information on utilizing exhaust gas from an internal combustion engine to power a vapor compression cycle air conditioning system. The document also covers the efficiency of photovoltaic solar panels for the refrigeration system, as well as factors influencing the cooling level in the vehicle's cabin room. Additionally, it presents results and discussions related to the proposed cooling system, including diagrams illustrating the test rig and the relationship between cooling load, engine speed, and system performance.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about this pdf?\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
